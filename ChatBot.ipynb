{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMzmXh38nz59wvMcJBxQ7sk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaeSeokSong/MachineLearningModels/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96hYYUFzcaxY"
      },
      "source": [
        "# Google Drive Local Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHqDHk2ucc7M"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgHeq1Zcb7M2"
      },
      "source": [
        "# Install Morpheme analyzer\n",
        "*   [Reference](https://soohee410.github.io/compare_tagger)\n",
        "*   [Install](https://sanghyu.tistory.com/170)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtYcWqVsb5Xk"
      },
      "source": [
        "# okt, komoran, kkma\n",
        "# install konlpy (okt, komoran, kkma)\n",
        "%%bash\n",
        "apt-get update\n",
        "apt-get install g++ openjdk-8-jdk python-dev python3-dev\n",
        "pip3 install JPype1\n",
        "pip3 install konlpy\n",
        "\n",
        "# mecab (take a long time)\n",
        "# set env\n",
        "%env JAVA_HOME \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "# install konlpy (mecab)\n",
        "%%bash\n",
        "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
        "pip3 install /tmp/mecab-python-0.996"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GobPxVERuegZ"
      },
      "source": [
        "# Error Solution\n",
        "\n",
        "1. TypeError: startJVM() got an unexpected keyword argument 'convertStrings' [(JVM)](https://gyulogs.tistory.com/130)\n",
        "2. NameError: name 'Tagger' is not defined [(Mecab)](https://sosomemo.tistory.com/31)\n",
        "3. ParserError: Error tokenizing data. C error [(Pandas)](https://mskim8717.tistory.com/82)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpM2dDEuuesD"
      },
      "source": [
        "\"\"\" \n",
        "ERROR 1. TypeError: startJVM() got an unexpected keyword argument 'convertStrings'\n",
        "- Solution: /usr/local/lib/python3.7/dist-packages/konlpy/jvm.py, 67 line (convertStrings=True) comments processing and save jvm.py before import pakage\n",
        "\"\"\"\n",
        "\n",
        "\"\"\" \n",
        "ERROR 2. NameError: name 'Tagger' is not defined \n",
        "- Solution: Execute mecab.sh script (under code excute)\n",
        "\"\"\"\n",
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk \n",
        "!pip3 install konlpy JPype1-py3\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu59D-1sc93c"
      },
      "source": [
        "# Import\n",
        "*   [KoNLPy Reperence](https://konlpy-ko.readthedocs.io/ko/v0.4.3/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRaXnlVOWpot"
      },
      "source": [
        "# import for MechineLearning\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "\n",
        "# import Morpheme analyzer\n",
        "from konlpy.tag import Kkma, Komoran, Okt, Mecab\n",
        "from konlpy.utils import pprint\n",
        "\n",
        "# import etc\n",
        "import time\n",
        "\n",
        "%cd /content/drive/My Drive/DeepLearning/AI_KKH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtyggGY871Bm"
      },
      "source": [
        "# Funtion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aaczn0GQ71N4"
      },
      "source": [
        "\"\"\"\n",
        "Function about time comparison\n",
        "\n",
        "def pos_times(taggers, tagger_name, texts) :\n",
        "    time_list = []\n",
        "    for tagger in taggers :\n",
        "        print(type(tagger))\n",
        "        \n",
        "        t1 = time.time()\n",
        "        for text in texts :\n",
        "            pprint(tagger.pos(text))\n",
        "        \n",
        "        print(\"###################################\")\n",
        "        t2 = time.time()\n",
        "        time_list.append(t2 - t1)\n",
        "\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.bar(tagger_name, time_list, color=(0.4,0.7,0.5))\n",
        "    plt.title('Learning Time with .pos', fontsize=17)\n",
        "    plt.ylabel('total seconds')\n",
        "\"\"\"\n",
        "# Extract Data about kakao talk's content\n",
        "def data_extraction(x_list, y_list) :\n",
        "    for text in test.values :\n",
        "        for t in text : \n",
        "            if \"프로젝트 김대엽 클럽장\" in t :\n",
        "                ptext = t[(t.rfind(']') + 2) : len(t)]\n",
        "                if ptext.find(\"http\") == -1 and ptext != \"\" : y_list.append(ptext)\n",
        "            elif \"]\" in t :\n",
        "                ptext = t[(t.rfind(']') + 2) : len(t)]\n",
        "                if ptext.find(\"http\") == -1 and ptext != \"\" : x_list.append(ptext)\n",
        "\n",
        "# Auto calibrate spacing function\n",
        "def calibrate_spcaing(input_list) :\n",
        "    for text in input_list :\n",
        "        analyzedRes = mecab.pos(text)\n",
        "        for mecabR in analyzedRes :\n",
        "            if mecabR[1] == \"MAG\" :\n",
        "                try :\n",
        "                    startIdx = text.index(mecabR[0])\n",
        "                    if len(mecabR[0]) == 1 :\n",
        "                        if text[startIdx + 1] != \" \" and text[startIdx + 1].isalnum() : \n",
        "                            if text[startIdx + 2] != \" \" :\n",
        "                                repairIdx = input_list.index(text)\n",
        "                                input_list[repairIdx] = text[:startIdx] + text[startIdx] + \" \" + text[startIdx + 1 :]\n",
        "                    else : \n",
        "                        if text[startIdx + len(mecabR[0])] != \" \" and text[startIdx + len(mecabR[0])].isalnum() : \n",
        "                            if text[startIdx + len(mecabR[0]) + 1] != \" \" :\n",
        "                                repairIdx = input_list.index(text)\n",
        "                                input_list[repairIdx] = text[:startIdx] + text[startIdx : startIdx + len(mecabR[0])] + \" \" + text[startIdx + len(mecabR[0]) :]\n",
        "                except IndexError :\n",
        "                    continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxjmmKaVlO9p"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk3zCKMclQz2"
      },
      "source": [
        "\"\"\"\n",
        "ranking about time spent morpheme analyzing (The fastest is number one.)\n",
        "\n",
        "1. Mecab\n",
        "2. Komoran\n",
        "3. Okt\n",
        "4. Kkma\n",
        "\n",
        "Mecab is faster than Kkma about 30~40 times\n",
        "Mecab is faster than Okt about 10 times\n",
        "Mecab is faster than Komoran about 5 times\n",
        "\"\"\"\n",
        "\n",
        "# Early versions use okt and macab.\n",
        "mecab = Mecab()\n",
        "okt = Okt()\n",
        "\n",
        "\"\"\" \n",
        "ERROR 3. ParserError: Error tokenizing data. C error \n",
        "- Solution: add code in read_csv = , sep='\\t'\n",
        "\"\"\"\n",
        "test = pd.read_csv('KKH_20200129~20210707.txt', sep='\\t')\n",
        "\n",
        "# 1. Data extraction\n",
        "x_list = []\n",
        "y_list = []\n",
        "data_extraction(x_list, y_list)\n",
        "\n",
        "# 2. Space cailbrating\n",
        "calibrate_spcaing(y_list)\n",
        "calibrate_spcaing(x_list)\n",
        "\n",
        "# 3. Modeling\n",
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}